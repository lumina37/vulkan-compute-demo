// Double Buffer

#version 460

#extension GL_EXT_control_flow_attributes : enable

layout (local_size_x_id = 0, local_size_y_id = 1) in;

layout (binding = 0, std430) readonly buffer SrcMatA { vec4 srcMatA[]; };
layout (binding = 1, std430) readonly buffer SrcMatB { vec4 srcMatB[]; };
layout (binding = 2, std430) writeonly buffer DstMat { vec4 dstMat[]; };

layout (constant_id = 2) const uint M = 0;
layout (constant_id = 3) const uint N = 0;
layout (constant_id = 4) const uint K = 0;
layout (constant_id = 5) const uint BLOCK_TILE_M = 128;
layout (constant_id = 6) const uint BLOCK_TILE_N = 128;
layout (constant_id = 7) const uint BLOCK_TILE_K = 128;
layout (constant_id = 8) const uint THREAD_TILE_M = 16;
layout (constant_id = 9) const uint THREAD_TILE_N = 16;
layout (constant_id = 10) const uint THREAD_TILE_K = 16;
layout (constant_id = 11) const uint THREAD_SUBTILE_M = 8;
layout (constant_id = 12) const uint THREAD_SUBTILE_N = 8;
layout (constant_id = 13) const uint THREAD_SUBTILE_K = 8;
const uint BLOCK_TILE_VEC_N = BLOCK_TILE_N / 4;
const uint BLOCK_TILE_VEC_K = BLOCK_TILE_K / 4;
const uint THREAD_TILE_VEC_N = THREAD_TILE_N / 4;
const uint THREAD_TILE_VEC_K = THREAD_TILE_K / 4;
const uint THREAD_SUBTILE_VEC_N = THREAD_SUBTILE_N / 4;
const uint THREAD_SUBTILE_VEC_K = THREAD_SUBTILE_K / 4;
const uint STAGES = 2;

const uvec2 SHARED_EXTENT_A = uvec2(BLOCK_TILE_VEC_K, BLOCK_TILE_M);
const uvec2 SHARED_EXTENT_B = uvec2(BLOCK_TILE_VEC_N, BLOCK_TILE_K);
shared vec4 sharedA[STAGES][BLOCK_TILE_M][BLOCK_TILE_VEC_K];
shared vec4 sharedB[STAGES][BLOCK_TILE_K][BLOCK_TILE_VEC_N];

void zeroFillAccumulator(inout vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_VEC_N]) {
    [[unroll]] for (uint iterTM = 0; iterTM < THREAD_TILE_M; iterTM++) {
        [[unroll]] for (uint iterTN = 0; iterTN < THREAD_TILE_VEC_N; iterTN++) {
            regAccumulator[iterTM][iterTN] = vec4(0);
        }
    }
}

void loadGlobalToShared(uvec2 globalCoord, uvec2 globalExtent, uint globalRowStride, bool loadA, uint stage) {
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uint localIndex = gl_LocalInvocationIndex;

    const uint groupThreadCount = groupSize.x * groupSize.y;
    const uint loadsPerThread = globalExtent.x * globalExtent.y / groupThreadCount;

    for (uint i = 0; i < loadsPerThread; i++) {
        const uint linearIdx = i * groupThreadCount + localIndex;
        const uvec2 srcOffset = uvec2(linearIdx % globalExtent.x, linearIdx / globalExtent.x);
        const uvec2 srcCoord = globalCoord + srcOffset;
        const uint srcIndex = srcCoord.y * globalRowStride + srcCoord.x;

        const uvec2 dstCoord = srcOffset;
        if (loadA) {
            sharedA[stage][dstCoord.y][dstCoord.x] = srcMatA[srcIndex];
        } else {
            sharedB[stage][dstCoord.y][dstCoord.x] = srcMatB[srcIndex];
        }
    }
}

void computeSubThreadTile(inout vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_VEC_N], uint iterTM, uint iterVecTN, uint stage) {
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uvec2 localID = gl_LocalInvocationID.xy;

    vec4 regA[THREAD_SUBTILE_VEC_K];
    vec4 regB[THREAD_SUBTILE_K][THREAD_SUBTILE_VEC_N];

    [[unroll]] for (uint iterBK = 0; iterBK < BLOCK_TILE_K; iterBK += THREAD_TILE_K) {
        [[unroll]] for (uint iterTK = 0; iterTK < THREAD_TILE_K; iterTK += THREAD_SUBTILE_K) {
            [[unroll]] for (uint iterSubTK = 0; iterSubTK < THREAD_SUBTILE_K; iterSubTK++) {
                const uint sharedCoordYB = iterBK + iterTK + iterSubTK;
                [[unroll]] for (uint iterVecSubTN = 0; iterVecSubTN < THREAD_SUBTILE_VEC_N; iterVecSubTN++) {
                    const uint sharedCoordVecXB = (iterVecTN + iterVecSubTN) * groupSize.x + localID.x;
                    regB[iterSubTK][iterVecSubTN] = sharedB[stage][sharedCoordYB][sharedCoordVecXB];
                }
            }

            [[unroll]] for (uint iterSubTM = 0; iterSubTM < THREAD_SUBTILE_M; iterSubTM++) {
                const uint regCoordY = iterTM + iterSubTM;
                const uint sharedCoordYA = (iterTM + iterSubTM) * groupSize.y + localID.y;

                [[unroll]] for (uint iterVecSubTK = 0; iterVecSubTK < THREAD_SUBTILE_VEC_K; iterVecSubTK++) {
                    const uint sharedCoordVecXA = (iterBK + iterTK) / 4 + iterVecSubTK;
                    regA[iterVecSubTK] = sharedA[stage][sharedCoordYA][sharedCoordVecXA];
                }

                [[unroll]] for (uint iterVecSubTN = 0; iterVecSubTN < THREAD_SUBTILE_VEC_N; iterVecSubTN++) {
                    const uint regCoordVecX = iterVecTN + iterVecSubTN;
                    [[unroll]] for (uint iterVecSubTK = 0; iterVecSubTK < THREAD_SUBTILE_VEC_K; iterVecSubTK++) {
                        const uint regBaseYB = iterVecSubTK * 4;
                        regAccumulator[regCoordY][regCoordVecX] += regA[iterVecSubTK].x * regB[regBaseYB + 0][iterVecSubTN];
                        regAccumulator[regCoordY][regCoordVecX] += regA[iterVecSubTK].y * regB[regBaseYB + 1][iterVecSubTN];
                        regAccumulator[regCoordY][regCoordVecX] += regA[iterVecSubTK].z * regB[regBaseYB + 2][iterVecSubTN];
                        regAccumulator[regCoordY][regCoordVecX] += regA[iterVecSubTK].w * regB[regBaseYB + 3][iterVecSubTN];
                    }
                }
            }
        }
    }
}

void computeWithShared(inout vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_VEC_N], uint stage) {
    [[unroll]] for (uint iterTM = 0; iterTM < THREAD_TILE_M; iterTM += THREAD_SUBTILE_M) {
        [[unroll]] for (uint iterVecTN = 0; iterVecTN < THREAD_TILE_VEC_N; iterVecTN += THREAD_SUBTILE_VEC_N) {
            computeSubThreadTile(regAccumulator, iterTM, iterVecTN, stage);
        }
    }
}

void storeAccumulator(vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_VEC_N]) {
    const uvec2 groupID = gl_WorkGroupID.xy;
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uvec2 localID = gl_LocalInvocationID.xy;

    const uint globalBaseY = groupID.y * BLOCK_TILE_M + localID.y;
    const uint globalBaseVecX = groupID.x * BLOCK_TILE_VEC_N + localID.x;
    [[unroll]] for (uint iterTM = 0; iterTM < THREAD_TILE_M; iterTM++) {
        const uint globalCoordY = globalBaseY + iterTM * groupSize.y;
        [[unroll]] for (uint iterVecTN = 0; iterVecTN < THREAD_TILE_VEC_N; iterVecTN++) {
            const uint globalCoordVecX = globalBaseVecX + iterVecTN * groupSize.x;
            const uint dstIdx = globalCoordY * N / 4 + globalCoordVecX;
            dstMat[dstIdx] = regAccumulator[iterTM][iterVecTN];
        }
    }
}

void main() {
    const uvec2 groupID = gl_WorkGroupID.xy;

    // Accumulator
    vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_VEC_N];
    zeroFillAccumulator(regAccumulator);

    // Prologue
    uint stage = 0;
    const uvec2 globalCoordA = uvec2(0, groupID.y * BLOCK_TILE_M);
    loadGlobalToShared(globalCoordA, SHARED_EXTENT_A, K / 4, true, 0);// Load A

    const uvec2 globalCoordB = uvec2(groupID.x * BLOCK_TILE_VEC_N, 0);
    loadGlobalToShared(globalCoordB, SHARED_EXTENT_B, N / 4, false, 0);// Load B
    barrier();

    // Main-loop
    const uint blockBaseM = groupID.y * BLOCK_TILE_M;
    const uint blockBaseVecN = groupID.x * BLOCK_TILE_VEC_N;
    [[unroll]] for (uint iterK = BLOCK_TILE_K; iterK < K; iterK += BLOCK_TILE_K) {
        const uint nextStage = (stage + 1) % STAGES;

        const uvec2 globalCoordA = uvec2(iterK / 4, blockBaseM);
        loadGlobalToShared(globalCoordA, SHARED_EXTENT_A, K / 4, true, nextStage);// Load A

        const uvec2 globalCoordB = uvec2(blockBaseVecN, iterK);
        loadGlobalToShared(globalCoordB, SHARED_EXTENT_B, N / 4, false, nextStage);// Load B

        computeWithShared(regAccumulator, stage);

        stage = nextStage;
        barrier();
    }

    // Epilogue
    computeWithShared(regAccumulator, stage);

    // Store results
    storeAccumulator(regAccumulator);
}
