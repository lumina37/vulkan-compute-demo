// Double Buffer

#version 460

#extension GL_EXT_control_flow_attributes : enable

layout (local_size_x_id = 0, local_size_y_id = 1) in;

layout (binding = 0, std430) readonly buffer SrcMatA { vec4 srcMatA[]; };
layout (binding = 1, std430) readonly buffer SrcMatB { vec4 srcMatB[]; };
layout (binding = 2, std430) writeonly buffer DstMat { vec4 dstMat[]; };

layout (constant_id = 2) const uint M = 0;
layout (constant_id = 3) const uint N = 0;
layout (constant_id = 4) const uint K = 0;
layout (constant_id = 5) const uint BLOCK_TILE_M = 128;
layout (constant_id = 6) const uint BLOCK_TILE_N = 128;
layout (constant_id = 7) const uint BLOCK_TILE_K = 128;
layout (constant_id = 8) const uint THREAD_TILE_M = 16;
layout (constant_id = 9) const uint THREAD_TILE_N = 16;
layout (constant_id = 10) const uint THREAD_TILE_K = 16;
const uint THREAD_TILE_N_VEC = THREAD_TILE_N / 4;
const uint THREAD_TILE_K_VEC = THREAD_TILE_K / 4;
const uint STAGES = 2;

const uvec2 SHARED_EXTENT_A = uvec2(BLOCK_TILE_K / 4, BLOCK_TILE_M);
const uvec2 SHARED_EXTENT_B = uvec2(BLOCK_TILE_N / 4, BLOCK_TILE_K);
shared vec4 sharedA[STAGES][BLOCK_TILE_M][BLOCK_TILE_K / 4];
shared vec4 sharedB[STAGES][BLOCK_TILE_K][BLOCK_TILE_N / 4];

void zeroFillAccumulator(inout vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_N_VEC]) {
    [[unroll]] for (uint tm = 0; tm < THREAD_TILE_M; tm++) {
        [[unroll]] for (uint tn = 0; tn < THREAD_TILE_N_VEC; tn++) {
            regAccumulator[tm][tn] = vec4(0.0f);
        }
    }
}

void loadGlobalToShared(uvec2 globalCoord, uvec2 globalExtent, uint globalRowStride, bool loadA, uint stage) {
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uint localIndex = gl_LocalInvocationIndex;

    const uint groupThreadCount = groupSize.x * groupSize.y;
    const uint loadsPerThread = globalExtent.x * globalExtent.y / groupThreadCount;

    for (uint i = 0; i < loadsPerThread; i++) {
        const uint linearIdx = i * groupThreadCount + localIndex;
        const uvec2 srcOffset = uvec2(linearIdx % globalExtent.x, linearIdx / globalExtent.x);
        const uvec2 srcCoord = globalCoord + srcOffset;
        const uint srcIndex = srcCoord.y * globalRowStride + srcCoord.x;

        const uvec2 dstCoord = srcOffset;
        if (loadA) {
            sharedA[stage][dstCoord.y][dstCoord.x] = srcMatA[srcIndex];
        } else {
            sharedB[stage][dstCoord.y][dstCoord.x] = srcMatB[srcIndex];
        }
    }
}

void computeWithShared(inout vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_N_VEC], uint stage) {
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uvec2 localID = gl_LocalInvocationID.xy;

    vec4 regA[THREAD_TILE_K_VEC];// Only cache one row for row-major A
    vec4 regB[THREAD_TILE_K][THREAD_TILE_N_VEC];// Cache the whole B

    const uint threadSplitKCount = BLOCK_TILE_K / THREAD_TILE_K;
    for (uint iThreadSplitK = 0; iThreadSplitK < threadSplitKCount; iThreadSplitK++) {
        // Load B
        [[unroll]] for (uint tk = 0; tk < THREAD_TILE_K; tk++) {
            const uint sharedCoordY = iThreadSplitK * THREAD_TILE_K + tk;
            [[unroll]] for (uint tn = 0; tn < THREAD_TILE_N_VEC; tn++) {
                const uint sharedCoordX = tn * groupSize.x + localID.x;
                regB[tk][tn] = sharedB[stage][sharedCoordY][sharedCoordX];
            }
        }

        // For each row in A
        [[unroll]] for (uint tm = 0; tm < THREAD_TILE_M; tm++) {
            // Load A
            const uint sharedCoordY = tm * groupSize.y + localID.y;
            [[unroll]] for (uint tk = 0; tk < THREAD_TILE_K_VEC; tk++) {
                const uint sharedCoordX = iThreadSplitK * THREAD_TILE_K_VEC + tk;
                regA[tk] = sharedA[stage][sharedCoordY][sharedCoordX];
            }

            // Actual compute
            [[unroll]] for (uint tn = 0; tn < THREAD_TILE_N_VEC; tn++) {
                [[unroll]] for (uint tk = 0; tk < THREAD_TILE_K_VEC; tk++) {
                    regAccumulator[tm][tn] += regA[tk].x * regB[tk * 4 + 0][tn];
                    regAccumulator[tm][tn] += regA[tk].y * regB[tk * 4 + 1][tn];
                    regAccumulator[tm][tn] += regA[tk].z * regB[tk * 4 + 2][tn];
                    regAccumulator[tm][tn] += regA[tk].w * regB[tk * 4 + 3][tn];
                }
            }
        }
    }
}

void storeAccumulator(vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_N_VEC]) {
    const uvec2 groupID = gl_WorkGroupID.xy;
    const uvec2 groupSize = gl_WorkGroupSize.xy;
    const uvec2 localID = gl_LocalInvocationID.xy;

    const uvec2 globalCoordBase = uvec2(groupID.x * BLOCK_TILE_N / 4, groupID.y * BLOCK_TILE_M);
    [[unroll]] for (uint tm = 0; tm < THREAD_TILE_M; tm++) {
        [[unroll]] for (uint tn = 0; tn < THREAD_TILE_N_VEC; tn++) {
            const uint globalCoordY = globalCoordBase.y + tm * groupSize.y + localID.y;
            const uint globalCoordX = globalCoordBase.x + tn * groupSize.x + localID.x;
            const uint dstIdx = globalCoordY * N / 4 + globalCoordX;
            dstMat[dstIdx] = regAccumulator[tm][tn];
        }
    }
}

void main() {
    const uvec2 groupID = gl_WorkGroupID.xy;

    // Accumulator
    vec4 regAccumulator[THREAD_TILE_M][THREAD_TILE_N_VEC];
    zeroFillAccumulator(regAccumulator);

    // Prologue
    uint stage = 0;
    const uvec2 globalCoordA = uvec2(0, groupID.y * BLOCK_TILE_M);
    loadGlobalToShared(globalCoordA, SHARED_EXTENT_A, K / 4, true, 0);// Load A

    const uvec2 globalCoordB = uvec2(groupID.x * BLOCK_TILE_N / 4, 0);
    loadGlobalToShared(globalCoordB, SHARED_EXTENT_B, N / 4, false, 0);// Load B
    barrier();

    // Main-loop
    const uint blockBaseM = groupID.y * BLOCK_TILE_M;
    const uint blockBaseN = groupID.x * BLOCK_TILE_N;
    const uint blockSplitKCount = K / BLOCK_TILE_K;
    for (uint iBlockSplitK = 1; iBlockSplitK < blockSplitKCount; iBlockSplitK++) {
        const uint nextStage = (stage + 1) % STAGES;
        const uint blockBaseK = iBlockSplitK * BLOCK_TILE_K;

        const uvec2 globalCoordA = uvec2(blockBaseK / 4, blockBaseM);
        loadGlobalToShared(globalCoordA, SHARED_EXTENT_A, K / 4, true, nextStage);// Load A

        const uvec2 globalCoordB = uvec2(blockBaseN / 4, blockBaseK);
        loadGlobalToShared(globalCoordB, SHARED_EXTENT_B, N / 4, false, nextStage);// Load B

        computeWithShared(regAccumulator, stage);

        stage = nextStage;
        barrier();
    }

    // Epilogue
    computeWithShared(regAccumulator, stage);

    // Store results
    storeAccumulator(regAccumulator);
}
